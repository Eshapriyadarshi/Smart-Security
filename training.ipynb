{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a0e003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e4c0051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['backward', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'follow', 'forward', 'four', 'go', 'happy', 'house', 'learn', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'visual', 'wow', 'yes', 'zero', '_background_noise_']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'D:\\data_speech_commands_v0.02'\n",
    "all_targets = [name for name in listdir(dataset_path) if isdir(join(dataset_path, name))]\n",
    "print(all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb3a430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets_path = r'D:\\voice_recognition'\n",
    "feature_sets_filename = 'all_targets_mfcc_sets.npz'\n",
    "model_filename = 'wake_word_stop_model.h5'\n",
    "wake_word1 = 'stop'\n",
    "wake_word2 = 'house'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36750e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x_train', 'y_train', 'x_val', 'y_val', 'x_test', 'y_test']\n"
     ]
    }
   ],
   "source": [
    "feature_sets = np.load(join(feature_sets_path, feature_sets_filename))\n",
    "print(feature_sets.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60cc5268",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = feature_sets['x_train']\n",
    "y_train = feature_sets['y_train']\n",
    "x_val = feature_sets['x_val']\n",
    "y_val = feature_sets['y_val']\n",
    "x_test = feature_sets['x_test']\n",
    "y_test = feature_sets['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd2f78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7717, 16, 16)\n",
      "(972, 16, 16)\n",
      "(957, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7945e02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20. 12. 14. ... 11. 26. 21.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0605dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "wake_word_index1 = all_targets.index(wake_word1)\n",
    "\n",
    "y_train = np.equal(y_train, wake_word_index1).astype('float64')\n",
    "y_val = np.equal(y_val, wake_word_index1).astype('float64')\n",
    "y_test = np.equal(y_test, wake_word_index1).astype('float64')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ca85a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "652b08c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03189300411522634\n",
      "0.9681069958847737\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_val) / len(y_val))\n",
    "print(1 - sum(y_val) / len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4cc17c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7717, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6073dc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7717, 16, 16, 1)\n",
      "(972, 16, 16, 1)\n",
      "(957, 16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "x_val = x_val.reshape(x_val.shape[0], \n",
    "                      x_val.shape[1], \n",
    "                      x_val.shape[2], \n",
    "                      1)\n",
    "x_test = x_test.reshape(x_test.shape[0], \n",
    "                        x_test.shape[1], \n",
    "                        x_test.shape[2], \n",
    "                        1)\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdc5513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "sample_shape = x_test.shape[1:]\n",
    "print(sample_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f15c6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, \n",
    "                        (2, 2), \n",
    "                        activation='relu',\n",
    "                        input_shape=sample_shape))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (2, 2), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Classifier\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54667236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 15, 15, 32)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 6, 6, 32)          4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 64)          8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 16,769\n",
      "Trainable params: 16,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41b82c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d07d5605",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7717 samples, validate on 972 samples\n",
      "Epoch 1/30\n",
      "7717/7717 [==============================] - 3s 403us/sample - loss: 0.1633 - acc: 0.9616 - val_loss: 0.1104 - val_acc: 0.9681\n",
      "Epoch 2/30\n",
      "7717/7717 [==============================] - 0s 45us/sample - loss: 0.1307 - acc: 0.9623 - val_loss: 0.1189 - val_acc: 0.9702\n",
      "Epoch 3/30\n",
      "7717/7717 [==============================] - 0s 46us/sample - loss: 0.1228 - acc: 0.9620 - val_loss: 0.1878 - val_acc: 0.9722\n",
      "Epoch 4/30\n",
      "7717/7717 [==============================] - 0s 46us/sample - loss: 0.1148 - acc: 0.9645 - val_loss: 0.0931 - val_acc: 0.9681\n",
      "Epoch 5/30\n",
      "7717/7717 [==============================] - 0s 46us/sample - loss: 0.1039 - acc: 0.9671 - val_loss: 0.0897 - val_acc: 0.9784\n",
      "Epoch 6/30\n",
      "7717/7717 [==============================] - 0s 46us/sample - loss: 0.0993 - acc: 0.9671 - val_loss: 0.0929 - val_acc: 0.9702\n",
      "Epoch 7/30\n",
      "7717/7717 [==============================] - 0s 45us/sample - loss: 0.0917 - acc: 0.9702 - val_loss: 0.1830 - val_acc: 0.9239\n",
      "Epoch 8/30\n",
      "7717/7717 [==============================] - 0s 46us/sample - loss: 0.0811 - acc: 0.9741 - val_loss: 0.0812 - val_acc: 0.9743\n",
      "Epoch 9/30\n",
      "7717/7717 [==============================] - 0s 45us/sample - loss: 0.0790 - acc: 0.9738 - val_loss: 0.1694 - val_acc: 0.9300\n",
      "Epoch 10/30\n",
      "7717/7717 [==============================] - 0s 45us/sample - loss: 0.0747 - acc: 0.9752 - val_loss: 0.0793 - val_acc: 0.9753\n",
      "Epoch 11/30\n",
      "7717/7717 [==============================] - 0s 44us/sample - loss: 0.0712 - acc: 0.9769 - val_loss: 0.0570 - val_acc: 0.9794\n",
      "Epoch 12/30\n",
      "7717/7717 [==============================] - 0s 46us/sample - loss: 0.0676 - acc: 0.9782 - val_loss: 0.0777 - val_acc: 0.9774\n",
      "Epoch 13/30\n",
      "7717/7717 [==============================] - 0s 45us/sample - loss: 0.0628 - acc: 0.9785 - val_loss: 0.0803 - val_acc: 0.9774\n",
      "Epoch 14/30\n",
      "7717/7717 [==============================] - 0s 46us/sample - loss: 0.0581 - acc: 0.9797 - val_loss: 0.0707 - val_acc: 0.9743\n",
      "Epoch 15/30\n",
      "7717/7717 [==============================] - 0s 45us/sample - loss: 0.0542 - acc: 0.9816 - val_loss: 0.0582 - val_acc: 0.9805\n",
      "Epoch 16/30\n",
      "7717/7717 [==============================] - 0s 49us/sample - loss: 0.0563 - acc: 0.9811 - val_loss: 0.0560 - val_acc: 0.9835\n",
      "Epoch 17/30\n",
      "7717/7717 [==============================] - 0s 46us/sample - loss: 0.0487 - acc: 0.9834 - val_loss: 0.0694 - val_acc: 0.9805\n",
      "Epoch 18/30\n",
      "7717/7717 [==============================] - 0s 47us/sample - loss: 0.0492 - acc: 0.9838 - val_loss: 0.0581 - val_acc: 0.9825\n",
      "Epoch 19/30\n",
      "7717/7717 [==============================] - 0s 51us/sample - loss: 0.0440 - acc: 0.9844 - val_loss: 0.0597 - val_acc: 0.9825\n",
      "Epoch 20/30\n",
      "7717/7717 [==============================] - 0s 50us/sample - loss: 0.0412 - acc: 0.9856 - val_loss: 0.0555 - val_acc: 0.9815\n",
      "Epoch 21/30\n",
      "7717/7717 [==============================] - 0s 48us/sample - loss: 0.0407 - acc: 0.9846 - val_loss: 0.0799 - val_acc: 0.9815\n",
      "Epoch 22/30\n",
      "7717/7717 [==============================] - 0s 46us/sample - loss: 0.0383 - acc: 0.9861 - val_loss: 0.0724 - val_acc: 0.9825\n",
      "Epoch 23/30\n",
      "7717/7717 [==============================] - 0s 45us/sample - loss: 0.0349 - acc: 0.9868 - val_loss: 0.0530 - val_acc: 0.9825\n",
      "Epoch 24/30\n",
      "7717/7717 [==============================] - 0s 46us/sample - loss: 0.0310 - acc: 0.9886 - val_loss: 0.1399 - val_acc: 0.9372\n",
      "Epoch 25/30\n",
      "7717/7717 [==============================] - 0s 48us/sample - loss: 0.0313 - acc: 0.9878 - val_loss: 0.0596 - val_acc: 0.9846\n",
      "Epoch 26/30\n",
      "7717/7717 [==============================] - 0s 46us/sample - loss: 0.0276 - acc: 0.9903 - val_loss: 0.1003 - val_acc: 0.9815\n",
      "Epoch 27/30\n",
      "7717/7717 [==============================] - 0s 47us/sample - loss: 0.0278 - acc: 0.9912 - val_loss: 0.0594 - val_acc: 0.9805\n",
      "Epoch 28/30\n",
      "7717/7717 [==============================] - 0s 45us/sample - loss: 0.0253 - acc: 0.9895 - val_loss: 0.0576 - val_acc: 0.9794\n",
      "Epoch 29/30\n",
      "7717/7717 [==============================] - 0s 44us/sample - loss: 0.0194 - acc: 0.9937 - val_loss: 0.0869 - val_acc: 0.9815\n",
      "Epoch 30/30\n",
      "7717/7717 [==============================] - 0s 44us/sample - loss: 0.0225 - acc: 0.9921 - val_loss: 0.0745 - val_acc: 0.9815\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    history = model.fit(x_train, \n",
    "                        y_train, \n",
    "                        epochs=30, \n",
    "                        batch_size=100, \n",
    "                        validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a383945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.save_model(model, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ebafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, y in enumerate(y_test):\n",
    "    if y == 1:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3d0aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(model_filename)\n",
    "for i in range(700,800):\n",
    "    print('Answer:', y_test[i], ' Prediction:', model.predict(np.expand_dims(x_test[i], 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b120fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7492f0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c3e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
